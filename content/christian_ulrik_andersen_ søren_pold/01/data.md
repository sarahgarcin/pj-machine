path: content/christian_ulrik_andersen_ søren_pold/01

----

content: 

----

index: 0

----

zoom: 1

----

xPos: 11.199999999999992

----

yPos: 1.7999999999999998

----

wordSpace: 0

----

nbOfFiles: 1

----

text: # MACHINE NETWORK READING
## Christian Soren

Text production has always been a central part of the development of the World Wide Web. Hypertext has become a complex conglomerate of references and citations that are spun together by a machinery of reading and writing. A central factor in the text machinery is Google. The scale and variety of Google’s activities signify how a control of production, distribution and consumption of text has become a new culture industry. 

This double-sided reading – where machines read how humans read – is not new. Interaction has always conditioned how computers register and reacts to users’ behaviour at the interface (this is what cybernetics is all about), but it has spread and been increasingly intensified with the interface industry and “surveillance capitalism” (Zuboff). We increasingly read texts that are re-written by algorithms programmed to mimic and manage our reading. Or, put differently, the texts we read integrate a large body of text, and the scripts that control this integration are (in more or less sophisticated ways) based on scripts that monitor reading behaviours. The conditions of reading are in this way significantly reconfigured by a new interface industry. 

What deep tendency lies within this new mode of production? Here are two brief examples.

The Readers Project created by John Cayley and Daniel Howe consists of a series of on-going experiments, installations, performances that relate to reading. These experiments are based on literary software, or programmed readers, that read texts, rewrite the texts, and present them to human readers; thereby making their reading visible and readable for the human reader. In other words, their literary interfaces visualize the programmed readers’ reading. Their reading patterns are inspired by cognitive studies of human reading, and range from something close to standard Western human reading (from left to right/top to bottom in the Simple Readers) to reading across what Cayley and Howe define as the typographic neighbourhood and page (Perigram Reader) to readers looking for specific letters in order to form words (Mesostic Reader) and readers following the grammatical structure of the text and finding alternatives words to fit this (Grammatical Lookahead Reader). Consequently, the different vectors of reading create routes through the text based on algorithmic rules, typographic neighbourhood, grammatical and semantic structures. 

In some of the interfaces the human readers can only read the texts through the programmed readers’ reading and re-writing of the texts; in others, the programmed readers’ routes are highlighted and obviously influence the human reading. The human readers thereby not only become conscious of their own reading process (including the grammars, habits and materials governing it), but also of the algorithmic readers’ grammars and (re-)writing of the text. The human reader ultimately meta-reads (Portela) and realises that his/her reading is enmeshed in a networked cybertext where reading is tracked and used to generate writing in an endless data loop that we also know from social media, but rarely are able to read directly.

----

blockSize: 8

----

