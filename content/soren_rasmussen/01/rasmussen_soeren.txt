# Imaging Probabilities, Imagining Possibilities: Machinic Pattern Recognition
## Søren Rasmussen

Representational meaning-making processes previously induced by traditional print culture have been replaced by the perpetual and modulatory processing of digital code in omnipresent, internetworked technology effectively affecting how we experience the world. Moving from analogue archives of motion capturing, preserving, and representing a moving world in its contemporary state, this shift is articulated as an anarchival paradigm to digital archives in motion (Røssaak, 2010; Ernst, 2013) operating in a time-space continuum imperceptible and inaccessible to the human sensorium. 
Previously appointed to the few, the construction and consignation of archived information today is delegated to the masses, as we participate like never before in mapping, tracking, and tracing our thoughts, bodies, and movements. This increase in participatory practices has paradoxically not sparked a new paradigm of individual expression, mutual understanding, and collective enunciation in which novelty and new relations can emerge, but has rather given way to neoliberal capture and reproduction of patterns through modulatory, programmed visions by means means of networked protocols (Chun, 2011; Galloway, 2004). We already live in societies of control (Deleuze, 1992) in which new technologies transform our lives, as we not only use but live with technology (Derrida, 1995, McCarthy & Wright, 2004). What happens when patterns are drawn in random data before human perception can make sense of it? What happens when nonsense is given meaning prior to pre-cognitive, affective perception?  
  
In Matter and Memory philosopher Henri Bergson distinguishes between two kinds of perceptual recognition: automatic (or habitual) recognition and attentive recognition. Bergson argues that modes of recognition emerge from and extend into movement, but that the differences lie in how memory interferes. Automatic recognition continues and prolongs perception in an anticipation of the immediate future (e.g. recognising a chair is for sitting). Attentive recognition makes a cut in perception by dwelling on the perceived object and analyzing it by projecting resembled memories onto it (e.g. the contours of clouds resembling a face). Such interference by memory in perception will happen “until other details that are already known come to project themselves upon those details that remain unperceived” (2011: 123). This projection of memory upon perception can result in minor details that are blown out of proportion in the vivid imposing of meaning on random data (e.g. seeing faces in clouds), a tendency in human perception known as 'apophenia' where the directed attention to minor details ends up defining the compositional whole.  
  
The above machinic recognition of patterns in random data is also how much data analysis by digital machines is performed. Google’s ambition to automatically classify images through their Deep Dream convolutional neural network is an example of patterning imposition that might result in unexpected outcomes much like human apophenia (cf. Steyerl, 2016).  
  
Through machine learning contemporary computational processing is moving from an automatic recognition of data only to also encompassing an unconscious form of attentive recognition, as neural networks automatically and attentively transform data to fit the model they operate by. Always processing and always calculating probabilities this new form of governance is truly modulatory and preemptive in its algorithmic reproduction of patterns in data.
By perpetually operating its algorithmic model on discrete data this new governance of modulatory control deprives us of the possibility of making a cut in the habitual, automatic recognition of patterns; it is actualising the world for us by imaging a world in terms of scripted protocols rather than allowing for imaginative leaps in counter-actualisations of what happens to us.  