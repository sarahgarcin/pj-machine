Let's revisit the methods of  machine learning using these principles to articulate prospective questions.   
Freire considers the relationship between the learner and the teacher as an opportunity of mutual liberation. To apply this to machine learning, we need to acknowledge the fact that both the people who teach machines and the machines themselves are entrapped in a relationship of oppression where both are loosing agency. To free algorithms and trainers together, both need to engage in a relationship where an iterative dialog is possible and where knowledge can circulate. This suggests to examine with great scrutiny how this relationship is framed and scripted. For instance, the data collection from human workers and the “ingestion” of the data by the algorithm are two distinct processes separated in time and space. Making it impossible for a dialogical relationship to happen. How to reconnect both processes and make machine learning become a dialogical process from the start?
Freire doesn't take for granted that a learner is “human” when he enters a pedagogical relationship. He only follows a process of humanization when the relationship unfolds. This resonates with a certain discourse in Artificial Intelligence[2] that softly erodes the human/machine divide as the algorithm learns. What is different is that Freire insists on maintaining the human/non-human demarcation. He doesn't make the distinction on an a-priori ontological quality of the beings but on their trajectory of liberation. What matters is how much human and machines are able to fight their common alienation. The core of the learning activity lies in a form of reflexivity where one follows a process of humanization through which he manages to get rid of the oppressor inside. We can then ask: “what kind of machine reflexivity can trigger human reflexivity and vice versa?”. And how this cross-reflexivity may help identify what constitutes the oppressor inside.
This leads us to the banking principle, according to which the oppressed is considered as an empty entity where knowledge is stored and repeated. This represents a complete erasure of what the learner already knows without knowing it. What does the trainer doesn't know he knows? What does the algorithm doesn't know it knows? What they both ignore, Freire would say, is their own knowledge. And to which extent this knowledge unknown to them is the knowledge of their oppressor or their own. 
To answer these questions they have only one choice: to engage in a dialog where two reflexivities are teaching each other the contours of their alienation and at the same time how to free themselves from it.  
<br><br><br><br> 

## Notes
[1]: See Freire's insistence in addressing this question as a political problem rather than an ontological one in his discussion with Seymour Papert: http://www.papert.org/articles/freire/freirePart2.html (Proximus NV → RIPE Network Coordination Centre → Telia Company AB → Amazon.com, Inc. → Amazon.com, Inc.)  
[2]: See Fei Fei Li's Ted Talk How we teach computers to see, https://www.youtube.com/watch?v=40riCqvRoMs (Proximus NV → Google Inc.)
