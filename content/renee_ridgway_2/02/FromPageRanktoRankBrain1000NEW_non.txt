### Signals

During the past 18 years, Google has constantly tweaked their proprietary algorithm, containing around 200 ingredients or ‘signals’ in the recipe.[3] “Signals are typically factors that are tied to content, such as the words on a page, the links pointing at a page, whether a page is on a secure server and so on. They can also be tied to a user, such as where a searcher is located or their search and browsing history.”[4] Links, content, keyword density, words in bold, duplicate content, domain registration duration and outbound link quality are some other examples of factors, or ‘clues’. One of the major changes in 2010 to the core algorithm of Page Rank was the ‘Caffeine’ update, which enabled an improvement in the gathering of information or indexing, instead of just sorting. ‘Panda’ was an update that was implemented in 2011 that downranks sites, which are considered lower quality, enabling higher quality pages to rise. In April 2012 Google launched the ‘Penguin’ update that attempts to catch sites, and now devalues spam instead of demoting (adjusting the rank) of the entire site. As of September 30, 2016, it updates in real time as part of the core algorithm.[5]   
  
Analogous to the components of engine that has had it parts replaced, where Penguin and Panda might be the oil filter and gas pump respectively, the launch of ‘Hummingbird’ in August 2013 was Google’s largest overhaul since 2001. With the introduction of a brand new engine the emphasis has shifted to the contextual — it’s less now about the keyword and more about the intention behind it — the semantic capabilities are what are at stake. Whereas previously certain keywords were the focus, at the moment  the other words in the sentence and their meaning are accentuated. Within this field of ‘semantic search’ the ‘relationality linking search queries and web documents’[6] is reflected with the ‘Knowledge Graph,’[7] along with ‘conversational search’ that incorporates voice activated enquiries.  
  
If Hummingbird is the new Google engine from 2013, the latest replacement part is then ‘RankBrain’. Launched around early 2015 it ostensibly ‘interprets’ what people are searching for, even though they may have not entered the exact keywords. ‘RankBrain’ is rumoured to be the third most important signal, after links and content (words) and infers the use of a keyword by applying synonyms or stemming lists.[8] The complexity level of the queries has gone up, resulting in an improvement of indexing web documents. User’s queries have also changed and are now not only keywords but also multi-words, phrases and sentences that could be deemed ‘long-tail’ queries. These need to be translated to a certain respect, from ‘ambiguous to specific’ or ‘uncommon to common,’ in order to be processed and analysed.[9] This reciprocal adaptability between the users and interface has been verified by previous research. Therefore it is probable that Google assigns these complex queries to groups with similar interests in order to ‘collaboratively filter’ them.[10]  
