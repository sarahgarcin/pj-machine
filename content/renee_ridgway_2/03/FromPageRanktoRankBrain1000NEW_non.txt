If Hummingbird is the new Google engine from 2013, the latest replacement part is then “RankBrain”. Launched around early 2015 it ostensibly “interprets” what people are searching for, even though they may have not entered the exact keywords. “RankBrain” is rumoured to be the third most important signal, after links and content (words) and infers the use of a keyword by applying synonyms or stemming lists.[8] The complexity level of the queries has gone up, resulting in an improvement of indexing web documents. User’s queries have also changed and are now not only keywords but also multi-words, phrases and sentences that could be deemed “long-tail” queries. These need to be translated to a certain respect, from “ambiguous to specific” or “uncommon to common,” in order to be processed and analysed.[9] This reciprocal adaptability between the users and interface has been verified by previous research. Therefore it is probable that Google assigns these complex queries to groups with similar interests in order to “collaboratively filter” them.[10]  
<br> 
### Machine learning
 
“Algorithms are not always neutral. They’re built by humans, and used by humans, and our biases rub off on the technology. Code can discriminate.”[11]  
   
As of June 2016 “RankBrain” is being implemented for every Google Search query and the SEO industry speculates it’s summarising the page’s content. The murmur is that the algorithm is adapting, or “learning” as it were from people’s mistakes and its surroundings. According to Google the algorithm learns offline, being fed historical batched searches from which it makes predictions. “And algorithms are made and remade in every instance of their use because every click, every query, changes the tool incrementally” (Gillespie 173). This cycle is constantly repeated and if the predictions are correct, the latest versions of “RankBrain”<br> go live.[12]  
   
Previously there were not computers powerful or fast enough, or the data sets were too small to carry out this type of testing. Nowadays the computation is distributed over many machines, enabling the pace of the research to quicken. This progress in technology facilitates a constellation or coming together of different capabilities from various sources, through models and parameters. Eventually the subject, or learner, in this case the algorithm, is able to predict, through repetition. Where is the human curator in all of this? “There is a case to be made that the working logics of these algorithms not only shape user practices, but also lead users to internalize their norms and priorities” (Gillespie 187). The question then is to what extent is there human adaption to algorithms in this filtering or curation process, how much do algorithms affect human learning and whether not only discrimination but also agency can be contagious.[13]