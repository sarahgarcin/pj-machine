path: content/renee_ridgway_2/03

----

content: 

----

index: 1

----

zoom: 1

----

xPos: 22.305263157894736

----

yPos: 1.7999999999999998

----

wordSpace: 0

----

nbOfFiles: 1

----

text: ### Machine learning
 
“Algorithms are not always neutral. They’re built by humans, and used by humans, and our biases rub off on the technology. Code can discriminate.”11  
   
As of June 2016 ‘RankBrain’ is being implemented for every Google Search query and the SEO industry speculates it’s summarising the page’s content. The murmur is that the algorithm is adapting, or ‘learning’ as it were from people’s mistakes and its surroundings. According to Google the algorithm learns offline, being fed historical batched searches from which it makes predictions. “And algorithms are made and remade in every instance of their use because every click, every query, changes the tool incrementally” (Gillespie 173). This cycle is constantly repeated and if the predictions are correct, the latest versions of ‘RankBrain’ go live.12  
   
Previously there were not computers powerful or fast enough, or the data sets were too small to carry out this type of testing. Nowadays the computation is distributed over many machines, enabling the pace of the research to quicken. This progress in technology facilitates a constellation or coming together of different capabilities from various sources, through models and parameters. Eventually the subject, or learner, in this case the algorithm, is able to predict, through repetition. Where is the human curator in all of this? “There is a case to be made that the working logics of these algorithms not only shape user practices, but also lead users to internalize their norms and priorities” (Gillespie 187). The question then is to what extent is there human adaption to algorithms in this filtering or curation process, how much do algorithms affect human learning and whether not only discrimination but also agency can be contagious.13

----

blockSize: 11

----

