path: content/brian_house/02

----

content: 

----

index: 0

----

zoom: 1

----

xPos: 1.4526315789473736

----

yPos: 1.7999999999999998

----

wordSpace: 0

----

nbOfFiles: 1

----

text: #MACHINE LISTENING
##Brian House

WaveNet is a "generative model of raw audio waveforms" developed by Google (van den Oord). It is a significant step forward in the synthesis of human-sounding voices by computers. This text, however, proceeds with the hypothesis that WaveNet is, perhaps more than anything else, a listening machine. In this capacity, it's a case study that suggests extending the limits of "acoustic knowledge" as theorized by Wolfgang Ernst.

Having been trained to speak, WaveNet nonetheless must be told what to say. If it _isn't_ told, however, it still generates "speech" that is "a kind of babbling, where real words are interspersed with made-up word-like sounds" (van den Oord) [1]. To my ear, this set of examples sounds _more realistic_ than the first. Perhaps the Turing test has been mis-designed&mdash;it's not the semantics that make this voice a "who" rather than an "it".

The inclusion of aspirations and a more musical sense of timbre, rhythm, and inflection in WaveNet is a function of the acoustic level at which it operates. Previous techniques of text-to-speech proceed from assumptions about how speech is organized&mdash;for example, they take the phoneme as speech's basic unit rather than sound itself. Where WaveNet is different is that it begins with so-called "raw" audio&mdash;that is, unprocessed digital recordings of human speech, to the tune of 44 hours worth from 109 different speakers (van den Oord). This data is feed into a convolutional, "deep" neural network, an algorithm designed to infer its own higher-order structures from elementary inputs. Subsequently, WaveNet generates speech one audio sample at a time. An intriguing aspect of the result is that WaveNet models not only the incidental aspects of speech in the training examples, but the very acoustics of the rooms in which they were recorded.

WaveNet's use of raw audio invokes what Ernst's dubs "acoustic knowledge" (Ernst 179). For him, such knowledge is a matter of media rather than cultural interpretation, embodied in the material processes by which sound is recorded on a phonographic disc. As he puts it, "these are physically real (in the sense of indexical) traces of past articulation, sonic signals that differ from the indirect, arbitrary evidence symbolically expressed in literature and musical notation" (Ernst 173). It is the "physically real frequency" (Ernst 173) that matters, the signal over semantics.

And yet analog recording media are not without their own acoustic inflections&mdash;the hiss and pops of tape or record are an added valence to the sonic events they reproduce. There is a "style" to media, a dialect in this addition. For Ernst, this indicates how the medium is inseparable from the recording. For me, that a phonograph is an imperfect listener grants it some affective agency; its status as a listener is in fact _predicated_ on having experienced in recording a change that is expressed in playback.

Such is the nature of sound. As Brandon Labelle puts it, "Sound is intrinsically and unignorably relational: it emanates, propagates, communicates, vibrates, and agitates; it leaves a body and enters others; it binds and unhinges, harmonizes and traumatizes; it send the body moving" (Labelle ix). Sound leaves an impression. _How_ we experience it and how we respond to it with our own particular bodies is conditioned by both physiology and past experience that marks us as listeners, whether non-biological or of a race, class, culture, species. Listening to something cannot just be, a la cybernetics, a matter of source + receiver&mdash;it is a material entanglement of these two together. 

From this perspective, Ernst's preoccupation with technical apparatuses is unnecessarily circumscribed. First, in the effort to assert acoustic knowledge over symbolic meaning, he sidesteps the material nature of human listening. The song that pops into your head, the voice that you recognize, the familiar acoustic quality of a habitual space&mdash;these experiences comprise acoustic knowledge that are not limited to technical inscription by the machine, but which are no less material as they reberberate within your own physiology. 

Ernst writes that "Instead of applying musicological hermeneutics, the media archaeologist suppresses the passion to hallucinate 'life' when he listens to recorded voices" (Ernst 60). Such a call for "unpassioned listening" (Ernst 25) is at odds with the interrelationality of listening and oddly replays the detached ocularity&mdash;the cold gaze&mdash;of colonial naturalism. Perhaps unpassioned listening is simply _not_ listening. Beyond semantics, it is the contextual cues of acoustics&mdash;such as dialect and room sound&mdash;that place a speaker embodied in a physical&mdash;and social&mdash;situation, and they do so by resonating with our own past acoustic experience. There is a chilling effect endemic to AI when an algorithm is presented as autonomous and unauthored, one which a dispassionate approach reinforces&mdash;we lose the bodily labor of those 109 speakers.

I'm suggesting here that a media materialist approach, while a powerful methodology, might be incomplete when we move beyond static media like a phonograph and approach the generative capacities of AI that are nonetheless capable of operating on this acoustic level. To modulate it, I'm proposing the _rhythmanalysis_ of Henri Lefebvre. Rhythm, here, might be compared to acoustic knowledge as it is a form of material memory, but it encompasses a greater sense of relationality, contingency, and potentiality. And Ernst's dispassion is contrasted by Lefebvre's warm bloodedness: “We know that a rhythm is slow or lively only in relation to other rhythms (often our own: those of our walking, our breathing, our heart)” (Lefebvre 10). Furthermore, these rhythms are not spontaneous or self-contained but are the result of a process of external influences. This he labels "dressage," or training, the acculturation of an individual to a socially produced articulation of time (Lefebvre 39). Deep neural networks are indeed trained&mdash;this could be described as inscription, but it realizes the necessity of its own continual re-performance.

The mechanism through which WaveNet "learns"&mdash;training a deep convolutional neural network (van den Oord)&mdash;is in fact an entrainment to human speech rhythms. With each recorded training example it hears, it changes. This is what makes it a listener, and a better one than a phonograph that only can receive a single sonic impression. If Ernst's strict division of the semantic versus the technical requires us to repress the very reverberations that make acoustic knowledge significant, we break the chain of embodied entrainments in which both us and the machine are co-implicated. Lefebvre moves in the opposite direction and muses how "If one could 'know' from outside the beatings of the heart of ... a person ..., one would learn much about the exact meaning of his words" (Lefebvre 4). Beating at nonhuman rates, WaveNet both listens and speaks differently, but it's talking to us.




----

blockSize: 19

----

